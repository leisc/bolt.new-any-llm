{"name":"ollama-ai-provider","dist-tags":{"latest":"0.16.1"},"versions":{"0.1.0":{"name":"ollama-ai-provider","version":"0.1.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-XyuHTnPSDN1I3SByuV0X6fNAdn64u19oE/BXAt1nMWyd2nKG/7uGZ+uNuwYRXxiAFIyQIFb75ip2OMqTHGcVYw==","shasum":"4d2b9fc223e79d97472a557e0cd1c9e5489fb9e0","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.1.0.tgz","fileCount":9,"unpackedSize":66703,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDb2PS69/O7ASOgHc/KUPr5SbLSrrz4IUJxLb+XbyQ/hwIhANZU9PxJiYziid2YwBwm7NjxVlcREzlk4W5B7UTbRKfD"}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.3","@ai-sdk/provider-utils":"0.0.5"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.31","@typescript-eslint/eslint-plugin":"^7.8.0","@typescript-eslint/parser":"^7.8.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.2.0":{"name":"ollama-ai-provider","version":"0.2.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-9NZ5QBjwgmSnDd4m0iBoPz3p7EenCwPV3tcYF0UOpkNjURaYabQQbW5F6V9+qTcN7dYo1HjobcaBNklqYttaXw==","shasum":"42cdb654db82da9c68bd69a1f28e760666850a4a","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.2.0.tgz","fileCount":9,"unpackedSize":65881,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDXhvDSPVgazWNWm6AVsPL7MYTKVaMdpu39mjNIdXni9AiARSdNj0SwiDFNkooc5tkSBFqLKOa4L8EbD0f7ddFsGlw=="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.3","@ai-sdk/provider-utils":"0.0.5"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.31","@typescript-eslint/eslint-plugin":"^7.8.0","@typescript-eslint/parser":"^7.8.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.3.0":{"name":"ollama-ai-provider","version":"0.3.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-4yPuvz75rTxDuvx5+u9Vr7lcjg+FQMJEg3t10IR6cVJCD0aA23zsoIlt5ecqfI63JB9/24rcRD/Ir7ZYmF4Riw==","shasum":"0a547448c36900a214d226e51a5af4e2472ef0d5","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.3.0.tgz","fileCount":9,"unpackedSize":70011,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDEVvCeMrZi9ac4070cLlhkq0pM+m8fR2Orz9LQTrwiOgIgTvQa4ivbPvMNn+YrmbS0SpBDiaGDJdPchWLj3/OzrMw="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.3","@ai-sdk/provider-utils":"0.0.5"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.31","@typescript-eslint/eslint-plugin":"^7.8.0","@typescript-eslint/parser":"^7.8.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.4.0":{"name":"ollama-ai-provider","version":"0.4.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-jWt1LbX7/BMJHMLsJKtSKxQXKWWSbu4cR8AA1L7n8BiBgjZLzr3tjLrCfPQO1GnbcxzqODBJq3XvpBTRcA2Q1Q==","shasum":"a69ac488c8295cdc5eecf655bfd9651db9cf764b","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.4.0.tgz","fileCount":9,"unpackedSize":77149,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIAXChM7yDL1PbtyMihnoHw6gh5ij7dgj5ERBj6CXxXl7AiBMUCUFa8AJNcgN/ee7hykzlU3O0jfuMBnbLc+Vw5iHlQ=="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.3","@ai-sdk/provider-utils":"0.0.6"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.31","@typescript-eslint/eslint-plugin":"^7.8.0","@typescript-eslint/parser":"^7.8.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.5.0":{"name":"ollama-ai-provider","version":"0.5.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-D3fX7ZwG1MYv+RQ+7fkInAjuWU+Y0uurgOGRj6HXFcbnTOVb9g3NqhANHsB/JvA8QsB6qn4NWPpKGZeHgvF/XQ==","shasum":"17adbd8edb068db07daa787ef0929ced0c40bfe8","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.5.0.tgz","fileCount":9,"unpackedSize":99796,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIGbB6xqyxdzz21KXzZCSGseqssypD+ZWAGGSxLyUVIJVAiBQXJYEMZG4OUTDOv+TRZX4dRoSinoXDt+zaaPcxU+6MQ=="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.3","@ai-sdk/provider-utils":"0.0.6"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.33","@typescript-eslint/eslint-plugin":"^7.8.0","@typescript-eslint/parser":"^7.8.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.5.1":{"name":"ollama-ai-provider","version":"0.5.1","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-cMDRWIAfhvk2zyPc6Dwy2ZSdD1JfbTkoaO7o5oI6PBeI1hH/xsGGRYUJpvxxr73uATbulZB2itBC6zg/RqUjYQ==","shasum":"27af45d5ebc80f9759edf403c6ba64ac30cba9ba","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.5.1.tgz","fileCount":9,"unpackedSize":99974,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIDglrnr3ObUlEcb3+TQ0Ip4JtICC+1awU9Vs7uC+c9uyAiEA5vtdz0e+YWnwgBNfPT/wXGED8ZXTtTwPt/zUWXAJqN8="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.5","@ai-sdk/provider-utils":"0.0.8"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.33","@typescript-eslint/eslint-plugin":"^7.9.0","@typescript-eslint/parser":"^7.9.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.6.0":{"name":"ollama-ai-provider","version":"0.6.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-LOV+1sjtIVNNHnTAPis369SBmmdAHa8Mz3JfDJ81YMjRiqfSVvQYCoMQqCiF52/WVRtJ6hSjzjbVjP6T1fvHSg==","shasum":"ef003a90a9fe1ec334467faf2d69e559f3dfbba7","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.6.0.tgz","fileCount":9,"unpackedSize":117072,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIDU/pKebkXoWAGltDrAmoVCaa+SeBPV5TTuqUcO2y9zoAiEA5iqt77m04TtBERjLDtQupAA2K0E2FgVo6MKI9t9dm/I="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.5","@ai-sdk/provider-utils":"0.0.8"},"devDependencies":{"@changesets/cli":"^2.27.1","@commitlint/cli":"^19.3.0","@commitlint/config-conventional":"^19.2.2","@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.33","@typescript-eslint/eslint-plugin":"^7.9.0","@typescript-eslint/parser":"^7.9.0","eslint":"^8.57.0","eslint-config-prettier":"^9.1.0","eslint-plugin-import":"^2.29.1","eslint-plugin-prettier":"^5.1.3","eslint-plugin-simple-import-sort":"^12.1.0","eslint-plugin-sort":"^3.0.2","eslint-plugin-unicorn":"^52.0.0","eslint-plugin-unused-imports":"^3.2.0","husky":"^9.0.11","lint-staged":"^15.2.2","prettier":"^3.2.5","tsup":"^8.0.2","typescript":"5.1.3","vite-tsconfig-paths":"^4.3.2","vitest":"^1.6.0","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.7.0":{"name":"ollama-ai-provider","version":"0.7.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-mw2NusrPkBJ7OxBLdRNNIVbXKtil//mj/7n393+9kj74gT6EKzyjf+j2v9AvFi0fJwnuW1YxnJpbuw1UjfdPRQ==","shasum":"2151391b77d7ae26846e0ac503a4477effc4742c","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.7.0.tgz","fileCount":8,"unpackedSize":132632,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQDcdOowbrOqgj7H+WQj9TJXrRSJbvYra+HkLEJaaFlPhwIhALWgIsQEDb3gMZoJ4sR0m8kDV11Y5aQ5VQSJqB0EjF1N"}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.5","@ai-sdk/provider-utils":"0.0.8","partial-json":"^0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.33","tsup":"^8.0.2","typescript":"5.1.3","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.8.0":{"name":"ollama-ai-provider","version":"0.8.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"7e23c8f801d6afacc531eb4e0ee4a7b95921f01b","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.8.0.tgz","fileCount":8,"integrity":"sha512-HWAfsYWYcvp7/tGanOSHGIJ0qWEsJgVs2To0Ki7O3T8JiyakcwyRZ7qjZkvfpp03In9XyT4LHNOlLFSECoq2xQ==","signatures":[{"sig":"MEUCIHTCgMXUUYSG73iBwTI8/gzbytoyrYo/jE/uWQoLo+CbAiEA7RjdUAJWKKnKIO82EpOgf7GKPVxM0EFbFax+9qfEhKE=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":128897},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"^0.1.7","@ai-sdk/provider":"0.0.11","@ai-sdk/provider-utils":"1.0.0"},"devDependencies":{"zod":"3.22.4","tsup":"^8.1.0","typescript":"5.1.3","@types/node":"^18.19.39","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.9.0":{"name":"ollama-ai-provider","version":"0.9.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"de5724f5acd778281cb29e42b18225e637acef8f","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.9.0.tgz","fileCount":9,"integrity":"sha512-RpxjGLtyjj0jmsw5XL7zxbnGA6dRh9iWouV2cAcS1PFTVYRAyavBHeWxefZx4U+75m2tdv6U78wGTuy6PzyEsw==","signatures":[{"sig":"MEYCIQDKCDOVbMy/6Q3GU97cHVWqhFXMcKG9eXaKbFU10CpGrQIhAMGojwahG/I34Ct4iN5I6Av6GE1EQDf1OwMk7+EbO9vG","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":133767},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"^0.1.7","@ai-sdk/provider":"0.0.11","@ai-sdk/provider-utils":"1.0.0"},"devDependencies":{"zod":"3.22.4","tsup":"^8.1.0","typescript":"5.1.3","@types/node":"^18.19.39","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.9.1":{"name":"ollama-ai-provider","version":"0.9.1","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"d85c1cea160f78df19a6ab707992eda87b0adf4e","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.9.1.tgz","fileCount":9,"integrity":"sha512-aIiuRiXAI0XFWIyqL5Zo2Mok2aFzEpr7NbtNucGew6Jhmsfzg9NPhVWQy+5MhnaTtgp+X+2zlOqjI5Yfn5/dDg==","signatures":[{"sig":"MEUCIQCMMl58vQLHm9vaKttii+Fgf7FwEvOE/IORWljAAyfzPAIgImxEgBP+VniL5smdi47nYemXUAnxDNvbqRrwaezFU+M=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":133541},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"^0.1.7","@ai-sdk/provider":"0.0.11","@ai-sdk/provider-utils":"1.0.0"},"devDependencies":{"zod":"3.22.4","tsup":"^8.1.0","typescript":"5.1.3","@types/node":"^18.19.39","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.10.0":{"name":"ollama-ai-provider","version":"0.10.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-ppzofC1JtB8yQ2TRAGm6I9ppoRSpXZGQV4u5ez2JAQ5hwnkJKULgEg5Hc4rt84ErF3MpEIpG1ZSBV4njlL6LPQ==","shasum":"e48586efd3a86fc9c88fe2bf0e167fb541c452a1","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.10.0.tgz","fileCount":9,"unpackedSize":142068,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDlXIrY7G8M5ZwH5uIU+/eLCHsR2tStcHW5y2F72TSnywIgK84hLHmgKorH9wjDCJKHWI0WqtZXIHtVmKTsYl5U6rc="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.11","@ai-sdk/provider-utils":"1.0.0","partial-json":"^0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.39","tsup":"^8.1.0","typescript":"5.1.3","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.11.0":{"name":"ollama-ai-provider","version":"0.11.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-zobsS8pZJ7IUfqQF+QiqWBG92ocm4fHpV+iXUCXoFtNMSN65Nr3v0TyW2sTooku3BVm9EmOBeMenKSOIv7h5Sw==","shasum":"15f4a94422eaeb35497e3bd7b5ee4dae602eb28c","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.11.0.tgz","fileCount":9,"unpackedSize":134755,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDQG8KJmOg58VOZiRSn/2P3praWBGp2sEsMAXqos4pQ4wIgUYpGhSzwlHHRSgJbVWFsehAcmFWs9ErnH2gVVJ7WJTY="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.14","@ai-sdk/provider-utils":"1.0.5","partial-json":"0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.39","tsup":"^8.1.0","typescript":"5.1.3","zod":"3.22.4"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.12.0":{"name":"ollama-ai-provider","version":"0.12.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-m9/CSY4ggCM7qMJ2oUYhOxmG2zu4hzp5Dot3qLLn0Q6Tq/0AqF8ZUs82A+YWnu358GfvMqVthimMXt0poeNbJg==","shasum":"7fc7aa5705091298cc4b8acbbada824185598e40","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.12.0.tgz","fileCount":9,"unpackedSize":140901,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEUCIQDRZ2cKUFZ6SXc3JuwPeX35/QhrR1rJR0T2Xxpii5tJogIgQ+QY7J8wiAU9+HxjsBXFyi9RfJ5tG4C3n0dSqG+VHmg="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.15","@ai-sdk/provider-utils":"1.0.7","partial-json":"0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.43","tsup":"^8.2.4","typescript":"5.1.3","zod":"3.23.8"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.12.1":{"name":"ollama-ai-provider","version":"0.12.1","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-WqCLEgqTwgEaO5kOlndHfCJawDLP2tbIicLy6rSKR+KrVDiLkYiOdTfk1eVMvm5KTDUYGXZBcowhQC17Ceayag==","shasum":"bd22b9abe5703a2f27a61f9a427c0259e85f13f8","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.12.1.tgz","fileCount":9,"unpackedSize":141220,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIF1EcGo3/mHICUu2haPvxllGmlE5wZgbLsHVo7xLAYRQAiBE9VLpPpUw7ZjD2F/oUa5AcJho2M4O6Vc+dyl/9PgXug=="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.21","@ai-sdk/provider-utils":"1.0.16","partial-json":"0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.43","tsup":"^8.2.4","typescript":"5.5.4","zod":"3.23.8"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.13.0":{"name":"ollama-ai-provider","version":"0.13.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-ZEtKD6ixxLIVLVRIZMh4yl0HGcdc8RotJW4ncdeAYXYT3fJ3LMvbatv9x8BeFkeb6+xy8Smc+4DbPMVFT+cjug==","shasum":"348bd6e09127f734bd1de9a59da0660cbaa9688e","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.13.0.tgz","fileCount":9,"unpackedSize":141356,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCIDUtGuoHjiPKdq29770/dstebCoBZ3UBU2b5IUoCN+xsAiBsRurwOonKUnbelbYK/FxLy+0+HomHDzen7N9NOKYHjg=="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.22","@ai-sdk/provider-utils":"1.0.17","partial-json":"0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.46","tsup":"^8.2.4","typescript":"5.5.4","zod":"3.23.8"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.14.0":{"name":"ollama-ai-provider","version":"0.14.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"3d1b543772beab141ea8f7d2387a170a95e7fc58","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.14.0.tgz","fileCount":9,"integrity":"sha512-ARN1pdN8v1lj9ekKml1rjGrdlh2fhUNrhRcUwf1APM/Wh+LguZ4wqF1Vf+x/Pqg27ChaMpd9GNnVuvwtqGxQ2g==","signatures":[{"sig":"MEQCIAUJfmOQXwNXl0VFM2GXktuF+li6QFT4UK6iu2ZzA3XGAiAeuMp+d98n9xne6hqS52wfXdNUCvrnb+4Ym34CvmeC+A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":141356},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"0.1.7","@ai-sdk/provider":"0.0.23","@ai-sdk/provider-utils":"1.0.18"},"devDependencies":{"zod":"3.23.8","tsup":"^8.2.4","typescript":"5.5.4","@types/node":"^18.19.46","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.15.0":{"name":"ollama-ai-provider","version":"0.15.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"b009e8657693de7f342e6f3937e9e260805bb52b","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.15.0.tgz","fileCount":9,"integrity":"sha512-pBRv2PjOPFdjB2fxOcu4dV3oT6NUxUI+V3c0Cu3r8Dwv6WmhHkRGLMscyRMU4Q2YVAtbghrvkfBGQmaqpMh/KQ==","signatures":[{"sig":"MEUCIQC3FBspC1bDP4dTW3/elNqVVTjZRAJn8fPMhuLkc9RrrAIgLPQeQWRKS5ojWEn5+lZVlUfCnBdhbc1mxRk9D/xGiTY=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":148582},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"0.1.7","@ai-sdk/provider":"0.0.23","@ai-sdk/provider-utils":"1.0.18"},"devDependencies":{"zod":"3.23.8","tsup":"^8.2.4","typescript":"5.5.4","@types/node":"^18.19.46","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.15.1":{"name":"ollama-ai-provider","version":"0.15.1","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"45f4598eeee5441886bc2442eaad596d637e1033","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.15.1.tgz","fileCount":9,"integrity":"sha512-eP1vxeJUgf1TdVyvJFqHEgU7eSnG7QYam4w1zTl4tokDh5eRw9aQtcdHYpq9xd5yU9b805v/Ghba6nVy1zOUew==","signatures":[{"sig":"MEUCIQCaCBMsFMJAttwWXD5kLkJJtb7JY8t1Wo6QEiKlaNsvrAIgBjZeV5VrLscDQ4RU3pxTCNyTutyWt5TSdxkVirVefeU=","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":149112},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"0.1.7","@ai-sdk/provider":"0.0.23","@ai-sdk/provider-utils":"1.0.19"},"devDependencies":{"zod":"3.23.8","tsup":"^8.2.4","typescript":"5.5.4","@types/node":"^18.19.46","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.15.2":{"name":"ollama-ai-provider","version":"0.15.2","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-bMDUlYmohulD87Xrv6meuftQdmFTygtrQywy6/gqdf1bTsJFP1VCx3MrisLFBzb4mMOj02NER7yZhiGIlAx30w==","shasum":"fa2cde1f0aa5e93aa4e201466a5fdbc9a65e1382","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.15.2.tgz","fileCount":9,"unpackedSize":149202,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEQCICjp7gwQCiyoIaCyUQPhY03cNb4dTucKIUFmiXIImIUhAiAGt/u4GI/AVRiInzTDuB3anUFB+Q1mEt+oD2M8nmZqOA=="}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.24","@ai-sdk/provider-utils":"1.0.20","partial-json":"0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.46","tsup":"^8.2.4","typescript":"5.5.4","zod":"3.23.8"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.16.0":{"name":"ollama-ai-provider","version":"0.16.0","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"shasum":"d80fbaff7f6aec016ae3a910d9c47c44a9a386ca","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.16.0.tgz","fileCount":9,"integrity":"sha512-8M04rSNl2tsZXzPvttUAkn5nptLlZXvGW+I/MYY6dECSE2C1ERONxgX15urYiJKpDNMniI+H/aILpFD0RFe/4g==","signatures":[{"sig":"MEQCIAYMWSCWDP4Me5WWBn3f5XqN37ePqoJ7yEDHKWrD2FrzAiA46oxVrE3UXrC7JS4Rkz5eLMfB/J0A5Z3tMKnoRlw86A==","keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA"}],"unpackedSize":157134},"engines":{"node":">=18"},"directories":{},"dependencies":{"partial-json":"0.1.7","@ai-sdk/provider":"0.0.26","@ai-sdk/provider-utils":"1.0.22"},"devDependencies":{"zod":"3.23.8","tsup":"^8.3.0","typescript":"5.5.4","@types/node":"^18.19.56","@edge-runtime/vm":"^3.2.0"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false},"0.16.1":{"name":"ollama-ai-provider","version":"0.16.1","description":"Vercel AI Provider for running LLMs locally using Ollama","dist":{"integrity":"sha512-0vSQVz5Y/LguyzfO4bi1JrrVGF/k2JvO8/uFR0wYmqDFp8KPp4+AhdENSynGBr1oRhMWOM4F1l6cv7UNDgRMjw==","shasum":"3238d4d36c630ed7f152e3e1cf24b68eb0c244d4","tarball":"https://mirrors.cloud.tencent.com/npm/ollama-ai-provider/-/ollama-ai-provider-0.16.1.tgz","fileCount":9,"unpackedSize":157846,"signatures":[{"keyid":"SHA256:jl3bwswu80PjjokCgh0o2w5c2U4LhQAE57gj9cz1kzA","sig":"MEYCIQCVICqPIJUPi6wEeg4xkvteXDSdZKv4O4/zqv7e6dqASwIhAJ1OOMV5cjsftTNpyLdGwQzoIKHlYZJ92+f44IE/ZmIX"}]},"engines":{"node":">=18"},"directories":{},"dependencies":{"@ai-sdk/provider":"0.0.26","@ai-sdk/provider-utils":"1.0.22","partial-json":"0.1.7"},"devDependencies":{"@edge-runtime/vm":"^3.2.0","@types/node":"^18.19.56","tsup":"^8.3.0","typescript":"5.5.4","zod":"3.23.8"},"peerDependencies":{"zod":"^3.0.0"},"peerDependenciesMeta":{"zod":{"optional":true}},"_hasShrinkwrap":false,"hasInstallScript":false}},"modified":"2024-11-06T22:53:20.156Z","time":{"created":"2024-05-05T09:34:41.490Z","0.1.0":"2024-05-05T09:34:41.828Z","modified":"2024-11-06T22:53:20.156Z","0.2.0":"2024-05-06T04:47:37.296Z","0.3.0":"2024-05-07T18:03:15.972Z","0.4.0":"2024-05-10T18:24:19.506Z","0.5.0":"2024-05-11T17:28:18.388Z","0.5.1":"2024-05-14T16:48:19.709Z","0.6.0":"2024-05-15T20:20:39.127Z","0.7.0":"2024-05-19T08:20:11.748Z","0.8.0":"2024-06-28T18:25:26.400Z","0.9.0":"2024-06-29T09:18:52.298Z","0.9.1":"2024-06-30T08:37:19.689Z","0.10.0":"2024-07-07T08:12:00.019Z","0.11.0":"2024-08-03T18:07:00.722Z","0.12.0":"2024-08-07T08:59:06.268Z","0.12.1":"2024-08-22T18:31:08.532Z","0.13.0":"2024-08-27T16:11:03.016Z","0.14.0":"2024-09-07T08:21:27.651Z","0.15.0":"2024-09-13T21:01:50.115Z","0.15.1":"2024-09-23T15:33:18.289Z","0.15.2":"2024-10-10T17:31:31.885Z","0.16.0":"2024-10-27T10:31:52.625Z","0.16.1":"2024-11-06T22:53:19.965Z"},"cachedAt":1731221762949}